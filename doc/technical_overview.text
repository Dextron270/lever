<doc title="Technical overview"/>

This is a quick rundown through the main features of the
language. It is written for programmers that want to know
what Lever has to offer. 

<h1>Operators</h1>

Lever is a dynamically typed object based programming
language where objects provide enough invariance to provide
a type-inferenced variation of the language for "free".

Objects in Lever are accessed through operators. Operators
are callable objects that select their implementation
from their arguments. There are operators for...

<ul>
    <li>(==), hash: Equality between objects can be
    determined.</li>
    
    <li>call: Object can be called.</li>

    <li>(in)/getitem/setitem/iter: Object contains
    other objects, it can be indexed or iterated.</li>

    <li>product: Object can be broken into a
    tuple.</li>

    <li>pattern: Object can be used as a pattern to
    match other objects.</li>

    <li>cmp: Objects can be compared.</li>

    <li>(++) Objects can be concatenated together</li>

    <li>Arithmetic operators such as (+)/(-) allow
    arithmetic on objects.</li>

    <li>Attribute access is treated as a large group of
    operators.</li>

    <li>The user of the language may provide more operators
    if they are needed.</li>
</ul>

Whenever an operator is called, it may select its
implementation from a single or multiple arguments. If the
implementation is selected from a single argument then the
operator resolves to a method of that argument.

If the implementation of an operator is chosen from multiple
arguments, then a type of those arguments is extracted and
it is used to find an unique coercion into a single type.
Then that single type is used to select a method and the
arguments used for selection are converted into the same
type.

<h1>Coercions</h1>

Coercion is defined through a function 'unique_coercion'
that retrieves a set of types and returns an unique coercion
if there exists one.

The 'unique_coercion' function finds every type from the
set, that every other type in that set can be implicitly
coerced to. If it finds more than one coercion, then it
behaves as if there was no such type.

Generally coercions have to be defined on type basis, but
types can be marked base or composite types. There exist an
implicit, lifting coercion between base and composite types.

The coercion system allows great tools to be made for
symbolic computation and numerical analysis, and it allows
those tools to interoperate.

<h1>Invariant modules</h1>

Modules and all the contents of modules are enforced to be
invariant. This ensures modules are reusable within
different tasks in a process without leaking state between
those tasks.

Variance is determined on object-basis. That is, in two
objects of same type, one may be invariant and another may
be not. But type may also refer on only variant objects,
eg. mutable lists and dictionaries.

<h1>Type inference</h1>

A type inference can be run on any module that is loaded.
The results of the type inference can be memoized, reused
and passed around along the module.

Static type checking for turing-complete languages must be
incomplete. That means there are correct programs that are
rejected by the type checking. My viewpoint is that those
rejected programs include, not only interesting programs,
but also some useful ones. Therefore the type inference is
not required for all programs.

The main purpose for type inferencing is further refinement
of the software. This opens up new options that make
software development less error prone and more effective.

For example, it is possible to write a PNG decoder in Lever
that is as fast or even faster than the decoder written in
C.  This can be achieved by optimizing the paeth filtering
step that the decoder has to do after decompression.

<h1>Datatypes</h1>

Lever provides several primitive datatypes with behaviors
you cannot conveniently implement inside the language,
though almost everything is behind an operator that user
can define for his own types.

This is a result of having to split some types such as lists
due to the multiple ways they are used in a statically typed
environment. Besides there was a lot of challenge in getting
the type system arranged to fit both dynamic and static typing
into same object space.

For user defined datatypes I decided to provide parametric,
tagged unions. They allow the user to create abstract datatypes
that properly hide how they're implemented. They also encourage
writing of more immutable structures, and we can check that their
case clauses cover all possibilities there are.

All datatypes use a notion of operational equivalence defined
in the paper
<a href="http://home.pipeline.com/~hbaker1/ObjectIdentity.html"
>"Equal Rights for Functional Objects or, The More Things
Change, The More They Are the Same"</a>.

The operational equivalence means that if x == y, then there's
nothing you can do with x or y to distinguish them from each other.

<h1>Scoping rules</h1>

The scope is lexical and it is divided into global and local
variables. Closures capture the variables when they are
introduced and cannot write to parent's scope at all.

Decision of whether a variable is global or local variable
is taken by its appearance in the source program. If the
variable is written to, it immediately becomes local at that
point.

The liveness for variables are calculated by the flow
analysis in the frontend. It is impossible to use a variable
if the flow analysis cannot prove it exists in the use point.

<h1>Parsing</h1>

Parsing is driven from a file with a generic-purpose parser,
just like in the previous version. Changing the file changes
the language.

<h1>Coeffects</h1>

Coeffects manifest in structures that resemble dynamic scope
variables. Each coeffect defines a set of variables in a
module that have to be bound in the context where the function
using them gets called. 

The difference to the traditional dynamic scope is that the
the access to the dynamic variables end up described in the
type of the function if it is type inferenced.

<h1>Intepretation</h1>

The primary method used here to evaluate programs is through
interpreting them. As a temporary measure the interpretation
happens by loading JSON files and their contents into the
memory, then evaluating a bytecode in a virtual machine.

Encoding is designed such that it can be encoded into the
same IR that produced it. The IR is based on
"Horn-Clauses as an Intermediate Representation for Program
Analysis" written by Jorge Navas.

The bytecode is divided into procedures that take input and
output variables as arguments. The VM can only do
conditional jumps forward and in the endpoint of each jump
there's is required to be a terminal point that prevents
execution without a jump. Inside each procedure the
evaluation path forms a binary tree.

The virtual machine instructions are divided into 8 groups
by their encoding. The first bits in the opcode form a
flag that identifies the instruction's group. Some of the
instruction groups consists of only one instruction. I do
not specify the exact instruction format here because the
format may still require some additional work before a major
release. 

The simple instructions only consist of input and output
variables. Most of the instructions go into this group:
o_move, o_global, o_attr, o_item, o_true, o_false, o_call,
o_deref.

Boolean guards form an another major group, containing
o_is_true, o_eq, o_match and o_next. These may cause the VM
to jump and are encoded in two-parts, they all have possibility
for two output variable lists encoded in them, although only
o_match and o_next produce output values.

The program may branch directly into an another procedure in
the same compilation unit. It has instructions o_branch and
o_branchx for this purpose. The o_branchx holds a
conditional jump for exception handling. Although o_branchx
forms it's own instruction group, it is treated as a guard.

Closures and generators are implemented through o_frame
-instruction. This instruction creates closure frames by
capturing variables.

There are few instructions that do not produce output
variables. o_yield, o_yield_from can be only used within a
generator. o_raise raises an error, causing the procedure
stack to be unwound.

The source location is encoded through list of strings in
source -variable for the whole unit, and each procedure has
'sourcemap' attribute that contains sixtuples of integers:
[bytes, col0, lno0, col1, lno1, src_index]
