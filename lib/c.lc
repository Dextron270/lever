# Completion of this strategy is due to 0.9.0 milestone
# STRATEGY: Improve foreign function interface to extend it's capabilities.
#           Provide complete REPL+Integrated Editor suite for lever.
# 
# I want people to frown when they see lever FFI and then contempt their
# language do not have this kind of system. To do this it needs to be
# slightly better and get some more exposure.

# Powerful interactive programming is lever's staple feature. This means we
# need really powerfull integrated development environment embedded into the
# runtime. The first step would be to provide a REPL that does bit more than
# reading a line and printing another out.

# TACTIC: use readline via FFI
# motivation: 
#   Line-editing tools in console are a great way to prepare
#   for the needs of a real IDE early on. It is also a feature many
#   other dynamic language implementations lack.
#
# requirements:
#   Use of readline requires that callbacks are implemented,
#   It also requires that library variables are handled more like
#   ordinary memory entries, because readline relies on global variables.

#   Use of readline requires dynamic loading that interrupts if the
#   library isn't available.

#   Also we may want to use this feature async. Async readline that doesn't
#   get confused by printing lines out would be so
#   awesome that it gives a new meaning for awesome.

#   Use of readline requires good C header generation. The cffi-gen library
#   is clumsy to use and update. Partially my own fault because I relied on
#   LR parsing. 

#   I believe it'd be the time to implement cffi header generator in lever.

#   To do that we need a C parser. Wholly functioning C parser! With macro
#   preprocessor.

#   This motivates the storyline of c.lc

#   This library should implement C tokenizing and parsing.
#   The parts that are common when you need to this kind of things.

import fs, json

main = ():
    stdio_h = "/usr/include/stdio.h"
    source = fs.read_file(stdio_h)
    getch = string_getch(source)
    getch = trigraph_getch(getch) # Assume we run with -trigraphs, (for fun)

    #ch = getch()
    #while ch != ''
    #    print(ch) # yaaay!!!
    #    ch = getch()
    stream = LogicalCharacterStream(getch, 1, stdio_h)

    # Printing tokens out is easy way to see that the stream is correctly tokenized.
    file = stdio_h
    lno = 1
    unprinted = []
    while stream.current != ""
        token = token_chop(stream)
        if not token
            break
        filename = token[0]
        line = token[1]
        name = token[2]
        value = token[3]
        # This thing here is trying to imitate the weird line switching logic
        # of gcc token printer. I think I get it wrong. But then I'm not yet
        # handling macros either.
        if line != lno or filename != file
            if filename == file
                print(" ".join(unprinted))
                if lno < line and line < lno + 6
                    for i in range(lno, line-1)
                        print("")
                else
                    print("")
                    print("#", line, escape_string(filename))
            else
                print("")
                print("#", line, escape_string(filename))
            file = filename
            lno = line
            unprinted = []
        unprinted.append(stringify_token(name, value))
    if unprinted.length > 0
        print(" ".join(unprinted))

    # This is actually something exposed to user. The user can select a config
    # The config comes from pytci's gcc_probe
    # Ran it with gcc_probe.py gcc -m32
    # and without the -m32
    #config = json.read_file("/home/cheery/.local/cc-config-x86_64.json")

    #for search_path in config["includes"]
    #    readline_h = path(search_path) ++ "readline/readline.h"
    #    if fs.exists(readline_h)
    #        print(readline_h)
    #    history_h = path(search_path) ++ "readline/history.h"
    #    if fs.exists(history_h)
    #        print(history_h)

# This will not properly stringify macros, but they are easy to handle
# manually if it is ever needed.
stringify_token = (name, value):
    if name == 'string'
        return escape_string(value)
    elif name == 'char'
        return escape_string(value, "'")
    else
        return value

# hilariously, this will probably also work for Lever itself just fine.
# and perhaps I should provide it is as a library function.
escape_string = (string, terminal='"', esc=escape_sequences):
    out = [terminal]
    for ch in string
        n = ord(ch)
        if 0x20 <= n and n <= 0x7E or 0xFF < n  # who does remember this range? :)
            if ch == terminal
                ch = '\\' ++ ch
        else
            # Note this only works on unprintable ascii character range.
            a = "0123456789abcdef"[n >> 4]
            b = "0123456789abcdef"[n & 15]
            ch = '\\x' ++ a ++ b
            for item in esc.items()
                if item[1] == n
                    ch = '\\' ++ item[0]
        out.append(ch)
    out.append(terminal)
    return "".join(out)


# The tokenizer has been copied from pytci and then updated to make more sense.
# The preprocessor tokenizer, imitating the behavior of a popular C compiler.
token_chop = (stream):
    stream.skip_spaces()
    line_begin = false
    while stream.current == '\n'
        stream.advance()
        stream.skip_spaces()
        # Tokenizer must mark "#" as MACRO, if it
        # appears in the beginning of a "logical" line
        # If you follow where this is going to, you will see it will also
        # accept %: as macro token, because it is translated to "#".
        # But then ## and %:%: aren't accepted.
        line_begin = true
    if stream.current == ""
        return null
    lno = stream.lno
    # Identifier: any sequence of letters, digits, or underscores,
    #             which begins with a letter or underscore
    #             you may have to accept $ as a letter
    if stream.current.is_alpha() or stream.current == '_'
        value = stream.advance()
        while stream.current.is_alpha() or stream.current.is_digit() or stream.current == '_'
            value ++= stream.advance()
        return token(stream.filename, lno, "identifier", value)
    # String literals start with: " ", ' ' literals cannot cross lines.
    # there is no way to escape backslash in #include <...>
    if stream.current in ["'", '"']
        stream.comments = false
        terminal = stream.advance()
        string = ""
        while stream.current != terminal
            assert stream.current != "", "unterminated string"
            assert stream.current != "\n", "unterminated string"
            character = stream.advance()
            if character == '\\'
                string ++= escape_sequence(stream)
            else
                string ++= character
        stream.comments = true
        terminal = stream.advance()
        if terminal == "'"
            return token(stream.filename, lno, "char", string)
        elif terminal == '"'
            return token(stream.filename, lno, "string", string)
        else
            assert false, "error in tokenizing"
    # Preprocessing number: Formally, preprocessing numbers begin
    #                       with an optional period, a required
    #                       decimal digit, and then continue with
    #                       any sequence of letters, digits, underscores,
    #                       periods, and exponents. Exponents are the
    #                       two-character sequences 
    character = stream.advance()
    if character.is_digit() or character == "." and stream.current.is_digit()
        number = character
        while stream.current.is_alpha() or stream.current.is_digit() or stream.current in ['.', '_']
            character = stream.advance()
            number ++= character
            if character ++ stream.current in exponents
                number ++= stream.advance()
        return token(stream.filename, lno, "number", number)
    # Comments. Defined such that comments are replaced with spaces.
    # This works as well. Though in GCC you can disable single line comments.
    # Once there's need, we may do the same. Flag for the character stream should take care of it well.
    if character == "/" and stream.current == "/"
        while stream.current != "\n" and stream.current != ""
            stream.advance()
        return token_chop(stream)
    if character == "/" and stream.current == "*"
        stream.advance()
        ch = stream.advance()
        while ch != ""
            ch = stream.advance()
            if ch == "*" and stream.current == "/"
                stream.advance()
                return token_chop(stream)
        assert false, "unterminated comment, an error?"
    # Valid punctuation characters are listed lower below.
    if character in punctuators
        punc = character
        pair = punc ++ stream.current
        while pair in long_punctuators
            punc ++= stream.advance()
            pair = punc ++ stream.current
        if pair in digraphs
            punc = digraphs[punc ++ stream.advance()]
            if pair == "%:" and stream.current == "%" and stream.next_current == ":"
                stream.advance() # Hack to handle 4-character digraphs.
                stream.advance() # Only reason to look ahead twice.
                punc = "##"
            # Bit of C-trivia. GCC doesn't translate %:# to ##. Neither does this!
        if punc == '#' and line_begin
            return token(stream.filename, stream.lno, "macro", punc)
        return token(stream.filename, lno, punc, punc) # punctuation is named for parsing.
    return token(stream.filename, lno, "other", current)

escape_sequence = (stream):
    if stream.current in escape_sequences
        return stream.advance()
    string = stream.advance()
    #\xhh The character whose numerical value is given by hh interpreted as a hexadecimal number
    if string == 'x'
        code = get_hex(stream) ++ get_hex(stream)
        if code.length == 2
            return chr(parse_int(code, 16))
        return "\\" ++ string ++ code
    #\nnn The character whose numerical value is given by nnn interpreted as an octal number
    if is_octal_char(string)
        string ++= get_octal(stream) ++ get_octal(stream)
        if string.length == 3
            return chr(parse_int(string, 8))
    return "\\" ++ string

get_hex = (stream):
    if stream.current in hex_alphabet
        return stream.advance()
    return ""

get_octal = (stream):
    if is_octal_char(stream.current)
        return stream.advance()
    return ""

is_octal_char = (character):
    return character in octal_alphabet

token = (filename, lno, name, value=""):
    return [filename, lno, name, value]


hex_alphabet = set("0123456789ABCDEFabcdef")

octal_alphabet = set("01234567")

escape_sequences = {"a": 0x07, "b": 0x08, "f": 0x0C, "n": 0x0A, "r": 0x0D, "t": 0x09, "v": 0x0B, "\\": 0x5C, "'": 0x27, "\"": 0x22, "?": 0x3F}

exponents = set(["e+", "e-", "E+", "E-", "p+", "p-", "P+", "P-"])

punctuators = set([
    "!", "#", "$", "%", "&", "(", ")", "*", "+", 
    ",", "-", ".", "/", ":", ";", "<", "=", ">", "?", "[", 
    "\\", "]", "^", "_", "{", "|", "}", "~",
])

long_punctuators = set([
    "<=", ">=", "!=", "&&", "||", "++", "--", "==", "<<", ">>", "+=",
    "-=", "*=", "/=", "%=", "&=", "^=", "|=", "->", "..", "##",
    "...", "<<=", ">>="
])

digraphs = {"<%":"{", "&>":"}", "<:":"[", ":>":"]", "%:":"#", "%:%:":"##"}

# The stream of characters that come in from a file is the physical stream.
# We get logical character stream by translating trigraphs and joining lines
# ending with backslash.

# The tokenizer needs to look ahead two characters, but because C has escape
# for end of line, this will need some more character lookaheads to translate
# the physical lines into logical lines.
class LogicalCharacterStream
    +init = (self, getch, lno=1, filename=""):
        self.getch = getch
        self.lno = lno
        self.filename = filename
        self.current = '\n' # Begins with newline to get a subsequent hash
                            # character recognized as a macro token.
        self.ch1 = self.getch()
        self.ch2 = self.getch()
        self.ch3 = self.getch()

    # It's so simple to keep track of line numbers when you transform the
    # logical newline at the last possible moment.
    next_current = :property()
        get = (self):
            if self.ch1 == '\\' and self.ch2 == '\n'
                return self.ch3
            return self.ch1

    advance = (self):
        ch = self.current
        self.current = self.ch1
        self.ch1 = self.ch2
        self.ch2 = self.ch3
        self.ch3 = self.getch()
        if self.current == '\n'
            self.lno += 1
        # Here the physical lines turn into logical ones.
        while self.current == '\\' and self.ch1 == '\n'
            self.lno += 1             # Tracking by physical line numbers
            self.current = self.ch2   # is bit more difficult than it sounds
            self.ch1 = self.ch3       # at first.
            self.ch2 = self.getch()
            self.ch3 = self.getch()
        return ch

    is_space = (self):                  # Matters for 'define' macro after tokenizing.
        return self.current in spaces

    skip_spaces = (self):               # The tokenizer uses this twice.
        while self.current in spaces
            self.advance()

    skip_spaces_and_newlines = (self):  # Though I have forgotten why this was here...
        while self.current in spaces_and_newlines # And twice use of the above function
            self.advance()              # is also bit low to reason a break into function.

spaces = set('\x00 \t')
spaces_and_newlines = set('\x00 \t\n')

# The one of the most beloved features of C/C++.
# https://en.wikipedia.org/wiki/Digraphs_and_trigraphs#C
#
# When trigraphs are used this happens before the logical character stream.
trigraph_getch = (getch):
    ch0 = getch()
    ch1 = getch()
    return ():
        ch2 = getch()
        if ch0 == '?' and ch1 == '?' # This is equivalent to how big compilers
            try                      # are doing it.
                ch = trigraphs[ch2]  # Three-character window and checking if
                ch0 := getch()       # There's a trigraph on it.
                ch1 := getch()
                return ch
            except KeyError as _
                null
        ch = ch0
        ch0 := ch1
        ch1 := ch2
        return ch

trigraphs = {
    "=": "#",
    "/": "\\",
    "(": "[",
    ")": "]",
    "!": "|",
    "<": "{",
    ">": "}",
    "-": "~",
}

# The getch function works better for a tokenizer than an iterator, so
# we have this function to transform a string into a getch function.
string_getch = (string):
    gen = iter(string)
    return ():
        try
            ch = gen.next()
            if ch == '\r' # support CRLF, just in case some retards use them.
                return gen.next()
            return ch
        except UncatchedStopIteration as stop
            return "" # Some things are simpler when everything
                      # is a string. Therefore this is not a null.
