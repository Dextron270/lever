import tokenizer

doc = path("doc:/chartparser")

main = ():
    s = Nonterminal('s')
    a = Nonterminal('a')
    b = Nonterminal('b')
    x = Terminal('x')

    terminals = {
        "h": x,
        "i": x,
        "j": x,
        "k": x,
        "l": x,
        "m": x,
        "n": x
    }

    accept = s
    user_grammar = [
        Rule(s, [a, s]),
        Rule(s, []),
        Rule(a, [x]) ]

    parser = preprocess(user_grammar, accept)()
    input_string = "hijklmn"
    for token in input_string
        parser.step(terminals[token], token)

    print("accepted?", parser.accepted)
    print(repr(parser.traverse(
        (x, a):
            return a,
        (x):
            return "")))

# Main interface to the chart parser are the rules, terminals and nonterminals.
class Rule
    +init = (self, lhs, rhs, annotation=null):
        self.lhs = lhs
        self.rhs = rhs
        self.annotation = annotation

    +repr = (self):
        out = repr(self.lhs) ++ " -> " ++ repr_spaces(self.rhs)
        return out

repr_spaces = (seq, space=" "):
    out = ""
    for item in seq
        if out.length > 0
            out ++= space
        out ++= repr(item)
    return out

# Earlier I did not separate terminals from
# non-terminals because it was not strictly
# necessary. That turned out to confuse
# when designing grammars.
class Terminal
    +init = (self, name):
        self.name = name

    +repr = (self):
        if self.name
            return "@" ++ self.name
        return "<Terminal>"

class Nonterminal
    +init = (self, name):
        self.name = name

    +repr = (self):
        if self.name
            return self.name
        return "<Nonterminal>"

# The NNF grammar is divided into null rules and non-null rules.
# The null rules are unnecessary for the actual parsing engine,
# yet they are useful when interpreting the parse results.

# The user of the parsing library shouldn't have to worry about
# the detail that the grammar is processed.
preprocess = (user_grammar, default_accept):
    nullable = find_nullable(user_grammar)
    grammar = {}
    blankset = {}
    rules = build_nnf(user_grammar, nullable)
    for rule in rules
        if rule.rhs.length == 0
            try
                blankset[rule.lhs].append(rule)
            except KeyError as _
                blankset[rule.lhs] = [rule]
        else
            try
                grammar[rule.lhs].append(rule)
            except KeyError as _
                grammar[rule.lhs] = [rule]
    right_recursive = find_right_recursive(rules)
    return Initiator(grammar, blankset, right_recursive, default_accept)

# Earley-style parsing would suffer from nullable rules, so in
# the marpa-style parsing we get rid of the nullable rules.

# The result is a "nihilist normal form"
# Further reasoning about this can be found in the paper
# "Practical Earley Parsing" by Aycock & Horspool

# First we have to discover the nullable rules
find_nullable = (grammar):
    nullable = set()
    queue = []
    new_nullable = (symbol):
        if symbol not in nullable
            nullable.add(symbol)
            queue.append(symbol)
    inverse_lookup = {}
    new_lookup = (index, symbol):
        try
            inverse_lookup[symbol].append(index)
        except KeyError as _
            inverse_lookup[symbol] = [index]
    nonterminals = []
    nonnullables = []
    for rule in grammar
        if rule.rhs.length == 0
            new_nullable(rule.lhs)
        elif all_nonterminals(rule.rhs)
            index = nonnullables.length
            for x in rule.rhs
                if x != rule.lhs
                    new_lookup(index, x)
            nonterminals.append(rule.lhs)
            nonnullables.append(count_nonrec(rule))
    for n in queue
        for i in inverse_lookup.get(n, [])
            nonnullables[i] -= 1
            if nonnullables[i] == 0
                new_nullable(nonterminals[i])
    return nullable

all_nonterminals = (rhs):
    for x in rhs
        if not isinstance(x, Nonterminal)
            return false
    return true

all_nullable = (rhs, nullable):
    for x in rhs
        if x not in nullable
            return false
    return true

count_nonrec = (rule):
    s = 0
    for x in rule.rhs
        s += int(x != rule.lhs)
    return s

# Going through n bits in binary produces all possible permutations
# where a field is present and not present.
build_nnf = (grammar, nullable):
    result = []
    for rule in grammar
        order = 0
        for x in rule.rhs
            order += int(x in nullable)
        for i in range(1 << order)
            result.append(nihilist_rule(rule, i, nullable))
    return result

nihilist_rule = (rule, index, nullable):
    present = []
    rhs = []
    for symbol in rule.rhs
        shift = true
        if symbol in nullable
            if index & 1 == 0
                shift = false
            index >>= 1
        present.append(shift)
        if shift
            rhs.append(symbol)
    return Rule(rule.lhs, rhs, NNF(rule, present))

# The nihilist normal form rules are annotated with NNF nodes.
class NNF
    +init = (self, rule, present):
        self.rule = rule       # the original rule
        self.present = present # tells which fields are present in this rule.

# Conditions on whether an item is leo-eligible:
#   its rule is right recursive
#   it is quasi-complete
#   it is postdot-unique
find_right_recursive = (grammar):
    edges = []
    for rule in grammar
        if rule.rhs.length > 0
            right = rule.rhs[rule.rhs.length - 1]
            row = []
            for other in grammar
                row.append(other.lhs == right)
            edges.append(row)
        else
            row = []
            for other in grammar
                row.append(false)
            edges.append(row)
    warshall_transitive_closure(edges)
    right_recursive = set()
    i = 0
    for rule in grammar
        if edges[i][i]
            right_recursive.add(rule)
        i += 1
    return right_recursive

warshall_transitive_closure = (a):
    n = a.length
    for k in range(n)
        for i in range(n)
            if not a[i][k]
                continue
            for j in range(n)
                if not a[k][j]
                    continue
                a[i][j] = true
    return a


# The nullable set presents the same information as the blankset
# so we can discard it.
class Initiator
    +init = (self, grammar, blankset, right_recursive, default_accept):
        self.grammar = grammar
        self.blankset = blankset
        self.right_recursive = right_recursive
        self.default_accept = default_accept

    # TODO: Fix up the performance issue in REPR startup by allowing the
    #       caching of a grammar.
    +call = (self, accept=self.default_accept):
        parser = Parser(self, accept, [])
        # In an earley parser that uses NNF, empty input is a special case, that is taken care of here.
        if accept in self.blankset
            parser.output.append(SPPF(null, null, null, null))
        # The first chart column
        nodes = {}
        current = []
        leims = {}
        prediction(current, nodes, self.grammar, parser.chart, accept)
        for eim in current
            prediction(current, nodes, self.grammar, parser.chart, eim.postdot())
            cache_transitions(parser.chart, eim, null, leims)
        return parser

class Parser
    +init = (self, init, accept, output):
        self.chart = self.first = {}
        self.init = init
        self.accept = accept
        self.output = output

    step = (self, term, token, start=null, stop=null):
        init = self.init
        # completions proceed in non-deterministic manner,
        # until everything has been completed.
        current = []
        leims = {}
        transitions = {}
        nodes = {}
        output = []
        bottom = SPPF(start, stop, token, null)
        shift_eims(current, nodes, self.chart[term], bottom, init.right_recursive, leims)
        for eim in current
            # reduction
            cc = nodes[eim]
            if eim.is_completed()
                shift_eims(current, nodes, eim.origin.get(eim.rule.lhs, []), cc, init.right_recursive, leims)
                if eim.rule.lhs == self.accept and eim.origin == self.first
                    output.append(cc)
            prediction(current, nodes, init.grammar, transitions, eim.postdot())
            cache_transitions(transitions, eim, cc, leims)
        self.chart = transitions
        self.output = output

    accepted = property();
        get = (self):
            return self.output.length > 0

    expect = property();
        get = (self):
            return self.chart.keys()

    expecting = (self, symbol):
        return symbol in self.chart

    traverse = (self, postorder_cb,
            blank_cb=make_default_blank(self, postorder_cb),
            resolve_ambiguity=self.default_ambiguity_resolution):
        if self.output.length > 1
            # This is really weird in current context. I should probably
            # rethink this whole ambiguity resolution -thing.
            sppf = resolve_ambiguity(null, self.output)
        else
            sppf = self.output[0]
            if isinstance(sppf, SPPF) and sppf.cell == null
                return blank_cb(self.accept)
        res = traverse_sppf([sppf], postorder_cb, blank_cb, resolve_ambiguity)
        assert res.length == 1, "broken parse traverse"
        return res[0]

    default_ambiguity_resolution = (self, sppf):
        raise Error(repr(sppf))

make_default_blank = (parser, postorder_cb):
    blank_cb = (symbol):
        blanks = parser.init.blankset[symbol]
        if blanks.length != 1
            raise Exception("default_blank ambiguity")
        cell = blanks[0]
        return postorder_cb(expand(null, null, cell, blank_cb, iter([]))...)
    return blank_cb

prediction = (current, nodes, grammar, transitions, postdot):
    if isinstance(postdot, Nonterminal)
        for rule in grammar.get(postdot, [])
            eim = EIM(rule, 0, transitions)
            if eim not in nodes
                nodes[eim] = null
                current.append(eim)

cache_transitions = (transitions, eim, cc, leims):
    if not eim.is_completed()
        postdot = eim.postdot()
        trans = object();
            eim = eim
            cc = cc
            leo = null
        try
            transitions[postdot].append(trans)
        except KeyError as _
            if eim.rule in leims
                trans.leo = leims[eim.rule]
            transitions[postdot] = [trans]

shift_eims = (current, nodes, edges, cc, right_recursive, leims):
    if is_leo_eligible(edges, right_recursive)
        trans = edges[0]
        if trans.leo
            link = LEOLink(trans.leo.link, trans.eim.rule, trans.cc)
            leims[trans.eim.rule] = object();
                trans = trans.leo.trans
                link = link
            eim = trans.leo.trans.eim.next()
            assert eim not in nodes
                "assumption that a postdot unique eim does not appear twice"
            nodes[eim] = LEO(link, cc)
            current.append(eim)
        else
            leims[trans.eim.rule] = object();
                trans = trans
                link  = LEOLink(null, trans.eim.rule, trans.cc)
            shift_eim(current, nodes, trans.eim, trans.cc, cc)
    else
        for trans in edges
            shift_eim(current, nodes, trans.eim, trans.cc, cc)

is_leo_eligible = (edges, right_recursive):
    if edges.length != 1 # must be postdot-unique
        return false
    eim = edges[0].eim
    return eim.rule in right_recursive and eim.pos == eim.rule.rhs.length - 1 #quasi-complete

shift_eim = (current, nodes, eim, bb, cc):
    eim = eim.next()
    try
        sppf = nodes[eim]
        sppf.insert(bb, cc)
    except KeyError as _
        if bb
            start = bb.start
        else
            start = cc.start
        nodes[eim] = sppf = SPPF(start, cc.stop, eim.rule, Link(bb, cc))
        current.append(eim)

class EIM
    +init = (self, rule, pos, origin):
        self.rule = rule
        self.pos = pos
        self.origin = origin
#        assert 0 <= pos <= len(rule)

    postdot = (self):
        if self.pos < self.rule.rhs.length
            return self.rule.rhs[self.pos]
        return null

    next = (self):
        if self.postdot()
            return EIM(self.rule, self.pos + 1, self.origin)
        return null

    penult = (self):
        if self.pos + 1 == self.rule.length
            return self.postdot()

    is_predicted = (self):
        return self.pos == 0

    is_confirmed = (self):
        return self.pos > 0

    is_completed = (self):
        return self.pos == self.rule.rhs.length

    +hash = (self):
        return hash([self.rule, self.pos, self.origin])

    # Sometimes to resolve bugs, we need to see what's going on.
    +repr = (self):
        return repr(self.origin) ++ ":" ++
            repr(self.pos) ++ 
            ":" ++ repr(self.rule)
        
#    # TODO: String formatting
#    #    if isinstance(self.rule, Rule):
#    #    lhs = repr(self.rule.lhs)
#    #    pre = ' '.join(map(repr, self.rule.rhs[:self.pos]))
#    #    pos = ' '.join(map(repr, self.rule.rhs[self.pos:]))
#    #    return "{} -> {} * {} : {}".format(lhs, pre, pos, self.origin)
#    #    return object.__repr__(self)
#
%"=="[[EIM, EIM]] = (a, b):
    if a.rule != b.rule
        return false
    if a.origin != b.origin
        return false
    if a.pos != b.pos
        return false
    return true

class LEO
    +init = (self, left, cc):
        self.left = left
        self.cc = cc

    stop = property();
        get = (self):
            return self.cc.stop

    to_sppf = (self):
        left = self.left
        cc = self.cc
        while left
            bb = left.sppf
            if bb
                start = bb.start
            else
                start = cc.start
            cc = SPPF(start, cc.stop, left.rule, Link(bb, cc))
            left = left.left
        return cc

class LEOLink
    +init = (self, left, rule, sppf):
        self.left = left
        self.rule = rule
        self.sppf = sppf

class SPPF # Shared packed parse forest
    +init = (self, start, stop, cell, link):
        self.start = start
        self.stop = stop
        self.cell = cell
        self.link = link

    to_sppf = (self):
        return self

    is_leaf = (self):
        return self.link == null

    insert = (self, left, right):
        if self.link == null
            self.link = Link(left, right)
            return self.link
        link = self.link
        while true
            if link.left == left and link.right == right
                return link
            if link.link == null
                link.link = Link(left, right)
                return link.link
            link = link.link

    single = (self):
        result = []
        link = self.link
        while link.left
            if link.link
                return null
            result.append(link.right)
            link = link.left.link
        if link.link    # Fixed the samples/grammar_bug_0
            return null
        result.append(link.right)
        result.reverse()
        return result

    +iter = (self):
        # TODO: should probably be incremental?
        output = []
        finger = []
        # To produce all parses, the sppf is fingered through.
        link = self.link
        while finger.length > 0 or link
            while link.left
                finger.append(link)
                link = link.left.link
            # Now the link contains the head, while the tail is in the finger list.
            while link
                result = [link.right]
                for x in reversed(finger)
                    result.append(x.right)
                output.append(result)
                link = link.link
            # Now some portion of the finger is already iterated, and should be removed.
            while finger.length > 0 and not link
                link = finger.pop().link
        return iter(output)

## TODO: add string formatter to lever
## return "[{}:{}] {}".format(self.start, self.stop, self.cell)

class Link
    +init = (self, left, right, link=null):
        self.left = left
        self.right = right
        self.link = link


traverse_sppf = (stack, postorder_cb, blank_cb, resolve_ambiguity):
    rcount = 1
    sstack = []
    rstack = []
    while stack.length > 0
        sppf = stack.pop().to_sppf()
        if sppf.is_leaf()
            sstack.append(sppf.cell)
            rcount -= 1
        else
            result = sppf.single()
            if result == null
                result = resolve_ambiguity(sppf, ambiguity_traverser(sppf,
                    postorder_cb, blank_cb, resolve_ambiguity))
            if isinstance(result, Resolve)
                sstack.append(result.value)
                rcount -= 1
            else
                rstack.append(object();
                    rcount = rcount - 1
                    rlen = result.length
                    sppf = sppf)
                rcount = result.length
                stack.extend(reversed(result))
        while rcount == 0 and rstack.length > 0
            s = rstack.pop()
            rcount = s.rcount
            rlen = s.rlen
            sppf = s.sppf
            a = []
            for i in range(rlen)
                a.append(sstack.pop(sstack.length+i-rlen))
            # TODO: Here we do not really identify where the blank rule appears.
            #       That feature could be really useful sometimes.
            #       That information is available in the sppf.
            sstack.append(postorder_cb(expand(
                sppf.start, sppf.stop, sppf.cell, blank_cb, iter(a))...))
    sstack.reverse() # won't hurt.
    return sstack

ambiguity_traverser = (sppf, postorder_cb, blank_cb, resolve_ambiguity):
    return (stack):
        seq = traverse_sppf(stack,
            postorder_cb,
            blank_cb,
            resolve_ambiguity)
        return postorder_cb(expand(
            sppf.start, sppf.stop, sppf.cell, blank_cb, iter(seq))...)

class Resolve
    +init = (self, value):
        self.value = value

expand = (start, stop, cell, blank_callback, seq):
    if isinstance(cell.annotation, NNF)
        nnf = cell.annotation
        result = []
        i = 0
        for p in nnf.present
            if p
                result.append(seq.next())
            else
                result.append(blank_callback(nnf.rule.rhs[i]))
            i += 1
        return [nnf.rule, result, start, stop]
    return [cell, list(seq), start, stop]



# TODO: 'format_origin' depends on the lno/col positioning information.
# We may want to change this, as parsing is not necessarily constrained
# to text files.
class SyntaxError extends Exception
    +init = (self, message, location, source, at_eof=false):
        self.message = message
        self.location = location
        self.source = source
        self.traceback = null
        self.at_eof = at_eof

    +repr = (self):
        return format_origin(self.source, self.location, self.message)

class SyntaxErrorExpected extends SyntaxError
    +init = (self, expect, location, source, at_eof=false):
        self.expect = list(expect)
        self.location = location
        self.source = source
        self.traceback = null
        self.at_eof = at_eof

    +repr = (self):
        msg = [format_origin(self.source, self.location, " expected some of:")]
        expect = []
        for e in self.expect
            if e.name
                expect.append(e)
        expect.sort(symbol_lt)
        for symbol in expect
            msg.append("    " ++ symbol.name)
        return "\n".join(msg)

class SyntaxErrorExpected2 extends SyntaxError
    +init = (self, value, expect, location, source, at_eof=false):
        self.value = value
        self.expect = list(expect)
        self.location = location
        self.source = source
        self.traceback = null
        self.at_eof = at_eof

    +repr = (self):
        msg = [format_origin(self.source, self.location, " expected some of:")]
        if self.value
            msg.insert(0, "got:" ++ repr(self.value))
        expect = []
        for e in self.expect
            if e.name
                expect.append(e)
        expect.sort(symbol_lt)
        for symbol in expect
            msg.append("    " ++ symbol.name)
        return "\n".join(msg)

format_origin = (source, location, message=null):
    loc = [repr(location.lno), repr(location.col)]
    if message
        loc.append(message)
    if isinstance(source, path)
        loc.insert(0, source.to_string())
    elif source
        loc.insert(0, source)
    else
        loc.insert(0, "")
    return ":".join(loc)

symbol_lt = multimethod(2)
symbol_lt[[Terminal, Nonterminal]] = (a, b):
    return false

symbol_lt[[Nonterminal, Terminal]] = (a, b):
    return true

symbol_lt[[Nonterminal, Nonterminal]] = (a, b):
    return a.name < b.name

symbol_lt[[Terminal, Terminal]] = (a, b):
    return a.name < b.name


# TODO: There's no certain place where this should sit,
# but it currently depends on .col, .lno -detail.

# There's no certain place where this should sit. But
# it's relevant with chartparser so it sits here now.
class IndentParser
    +init = (self, pos=tokenizer.Position(0, 1), indent=null, dedent=null, newline=null):
        self.stack = []
        self.level = pos.col
        self.line = pos.lno
        self.indent = indent
        self.dedent = dedent
        self.newline = newline

    step = (self, parser, pos, source):
        if self.line < pos.lno
            while pos.col < self.level and parser.expecting(self.dedent)
                parser.step(self.dedent, null, pos, pos)
                self.level = self.stack.pop()
            if pos.col < self.level
                raise SyntaxError("uneven indent", pos, source)
            if pos.col == self.level and parser.expecting(self.newline)
                parser.step(self.newline, null, pos, pos)
            if pos.col > self.level and parser.expecting(self.indent)
                parser.step(self.indent, null, pos, pos)
                self.stack.append(self.level)
                self.level = pos.col
            self.line = pos.lno

    # This can be used to terminate dedent if the parsing cannot
    # continue otherwise. Though note that this function, and to
    # some extent the whole indent parser in its current form
    # provides bias for certain interpretations of the input.
    slip = (self, parser, pos, source):
        while parser.expecting(self.dedent)
            parser.step(self.dedent, null, pos, pos)
            self.level = self.stack.pop()

    # Most languages have a bug if this function returns false.
    finish = (self, parser, pos):
        while self.stack.length > 0 and parser.expecting(self.dedent)
            parser.step(self.dedent, null, pos, pos)
            self.level = self.stack.pop()
        return self.stack.length == 0
